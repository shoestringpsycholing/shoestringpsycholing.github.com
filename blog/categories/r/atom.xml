<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: R | Shoestring Psycholing]]></title>
  <link href="http://shoestringpsycholing.github.com/blog/categories/r/atom.xml" rel="self"/>
  <link href="http://shoestringpsycholing.github.com/"/>
  <updated>2012-11-07T15:07:28-05:00</updated>
  <id>http://shoestringpsycholing.github.com/</id>
  <author>
    <name><![CDATA[Scott Jackson]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Kruschke Chapter 2]]></title>
    <link href="http://shoestringpsycholing.github.com/blog/2012/11/03/kruschke-chapter-2/"/>
    <updated>2012-11-03T13:48:00-04:00</updated>
    <id>http://shoestringpsycholing.github.com/blog/2012/11/03/kruschke-chapter-2</id>
    <content type="html"><![CDATA[<p>(<a href="http://shoestringpsycholing.github.com/blog/2012/11/02/naive-bayesian">Here's a link to the intro and Chapter 1 discussion</a>)</p>

<p>In this chapter, Kruschke does a nice job of succinctly laying out the primary goals of statistical inferencing, and gives a pretty clear, intuitive description of what prior and posterior beliefs are about. To paraphrase in a nutshell, prior beliefs represent our beliefs (including level of uncertainty in those beliefs) before data collection or observation, and posterior beliefs reflect what we believe after taking data into account.</p>

<p>This chapter strikes me as a nice place to do some discussions in a class about what the goals of statistics are, the idea of updating beliefs via statistics, etc.  For example, I can easily see some people being uneasy about the idea of mathematical formulas determining beliefs, in a philosophical sense. Kruschke does touch on this briefly, mentioning basically that beliefs that cannot be influenced by data are essentially "out of bounds," but he does so in kind of a flippant way. I think even if we are talking about scientific beliefs, the idea of an analysis telling you what you <em>should</em> believe (and Kruschke does use the word "should") can be uncomfortable, and not entirely realistic.</p>

<p>To clarify, in case you're new to Bayesian inference, one of the concepts behind Bayesian inference is that it gives a clear mathematical formulation for how beliefs should be changed (there's that "should" again), given the prior beliefs and the data. For example, a detective might be able to express her beliefs about suspects in terms of relative probabilities. So maybe if a woman was murdered, there could be a relatively high prior belief that it was the jealous ex-husband, and relatively low prior belief that it was the woman's 2-year-old daughter. If the detective finds the daughter's fingerprints on the murder weapon, it may only slightly affect her (nearly zero) belief that the daughter did it, where finding the husband's fingerprints may make a big difference. The point is that Bayesian inference gives a mathematical framework for actually computing how beliefs should be updated. But given what people often mean when they talk about "beliefs," the idea of a mathematical system telling you how you should change your beliefs given some data might be uncomfortable.</p>

<p>Of course, once you get a little farther, the Bayesian concept of "belief" is pretty circumscribed and clear, and it doesn't quite mean what most people mean by "belief," but I could see this point in the book being a good place for some discussion along these lines in a class. Especially because it's such a different kind of approach compared to the null-hypothesis significance testing (NHST) way of thinking about things.  If NHST is new to you, too, the NHST way of thinking about things is more that you approach a set of data and ask "what are the odds that this data occurred this way purely by chance?"  And if you decide that the odds are sufficiently low (by convention in many fields, less than 5%, or 1-in-20 odds), then you draw the conclusion that the "null hypothesis" (the hypothesis that whatever you're looking at happened just by chance) is probably false. This comes up more directly later in the book, but that's the gist, if all this stats stuff is new to you.</p>

<p>But back to the three goals as Kruschke presents them: (1) estimation of parameter values, (2) prediction of data values, and (3) model comparison.  Depending on the context of who's reading this book, I could see the benefit of some more examples of these things, but the presentation in the text is nice and clear.  Kruschke makes an interesting point about Bayesian analysis "intrinsically adjust[ing] for model complexity" (p. 14), but the significance of this is likely to be lost on anyone not familiar with model comparison in other (e.g., NHST) methods. In terms of the audience of the book, I think these points will be much more interesting and meaningful to anyone who's actually done data analysis before, and they may fly right by someone who's relatively new to it.</p>

<p>Finally, Kruschke includes a short intro to the <a href="http://www.r-project.org/">R software and programming language</a>. There's not really a great way to introduce R in 7 pages, but Kruschke does a decent job of giving the minimum needed to help people get the ball rolling.  Again, here's another spot where his <a href="http://www.indiana.edu/~kruschke/DoingBayesianDataAnalysis/">website</a> outpaces the book already, because the website makes the excellent recommendation of using <a href="http://www.rstudio.org/">RStudio</a>, instead of the (IMHO) inferior  <a href="http://www.sciviews.org/Tinn-R/">Tinn-R</a>. No knock against the fine folks who put together Tinn-R.  This is just one of those things that makes it hard to write static books about R.  RStudio is a pretty new player in the GUI game, but it's quickly become the favorite for general users for a lot of good reasons.  In any case, Kruschke will not make you an expert at R. But he gives you enough to run through the code in the book, cookbook-style. I suspect for anyone needing to work with real data, some additional resources or expertise in R will be needed to go from raw data to Bayesian analysis. <strong>R pet peeve alert:</strong> throughout the book, Kruschke uses the style of using <code>=</code> instead of <code>&lt;-</code> for assignment. This may help many people coming from other programming languages, but it's a little non-idiomatic for R.  But this is a pretty inconsequential pet peeve, and since the book is about Bayesian analysis, not R coding style, I think overall this is not a bad choice.</p>

<p>In summary, it's a good chapter and covers a bunch of introductory bases.  Depending on who's reading the book, and what the goals are (class textbook vs. self-study), a good amount of supplementary material or discussion could be useful, or it could be fine to just skim this chapter to get on to the meatier stuff.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Naive Bayesian]]></title>
    <link href="http://shoestringpsycholing.github.com/blog/2012/11/02/naive-bayesian/"/>
    <updated>2012-11-02T07:04:00-04:00</updated>
    <id>http://shoestringpsycholing.github.com/blog/2012/11/02/naive-bayesian</id>
    <content type="html"><![CDATA[<h2>Huh?</h2>

<p>A big part of my day-to-day involves data analysis, usually statistical data analysis. The stats scene has been in some flux lately, at least in the fields I work in, and interestingly, I think a lot of that has resulted, directly or indirectly, from the availability of the <a href="http://www.r-project.org/">R statistical language/package</a>. Long story short, it has increased accessibility to methods that are not all that new in the scheme of things, but which have not been terribly accessible.  More on all that another day.</p>

<p>Today, the topic is <a href="http://en.wikipedia.org/wiki/Thomas_Bayes">Bayesian</a> stats. The word "Bayesian" is a bit of a buzz-word for a wide range of different topics in computational and statistical work, but despite this, it's a really important modern approach to data and analysis.  What exactly is it, and what's the big deal?  Damned if I know, but in an ongoing series of posts, I intend to find out a lot more, and share my thoughts here.</p>

<p>So here's the idea:  starting virtually from scratch, I'm going to walk through a recent <a href="http://www.indiana.edu/~kruschke/DoingBayesianDataAnalysis/">book</a> by <a href="http://www.indiana.edu/~kruschke/">John Kruschke</a>, and give my own knee-jerk reactions, as a kind of extended review of the book, and the usefulness of Bayesian methods for language scientists (and maybe others). Kruschke himself is a very um... <em>outspoken</em> advocate of Bayesian analysis (see this <a href="http://www.indiana.edu/~kruschke/AnOpenLetter.htm">"Open Letter"</a>), and while I'm generally pretty sympathetic and find most of these arguments pretty convincing, I'll try to take a skeptical stance when going through the book.</p>

<p>My own stats background is pretty hodge-podgy, but I can hold my own in comparison to most folks in my field. My hope is that by going through the book in this way, I'll get more out of the book myself, and it might help other folks decide whether looking into Bayesian stats could be worth their time, too.  Big props go to Amber Springer for getting a local reading group started on this book. I wasn't able to attend as much as I'd have liked to, but going to a couple of meetings really got the ball rolling for me, and I appreciate it!</p>

<h2>The Big Deal, in a nutshell</h2>

<p>If all this is utterly mysterious and the word "Bayesian" might as well be "Martian," here's the basic gist of why I'm spending time on this. "Traditional" stats in the fields I work in are more or less descended from seminal work by <a href="http://en.wikipedia.org/wiki/Ronald_Fisher">Ronald Fisher</a> and others, and can also be referred to as "Null Hypothesis Significance Testing." If you've ever looked for a "p-value" to tell you if your experiment "worked," this is the framework you're used to. It boils down to a system of making inferences based on data, because that's ultimately what we want, to look at data and have it tell us something so we can make inferential conclusions.  Like looking at language learning outcome measures and using those to tell you whether Teaching Method A was more effective than Teaching Method B. Or whatever.</p>

<p>The point made by folks like Kruschke is quite simply that the NHST system of making inferences is broken, and we need to switch to Bayesian methods, which involves a different system of making inferences from data. There has been quite the war within the field of statistics, with both sides (NHST and Bayesian) attacking the other program as obviously wrong and utterly misguided. My impression is that this polemic has faded a little, and other folks, like <a href="http://andrewgelman.com/">Andrew Gelman</a>, are not quite as divisive, but they often claim that Bayesian methods have distinct advantages over NHST methods. Wanting to understand what those advantages might be, and whether they could help with the sometimes very sticky data analysis situations I find myself in, are my main motivations.</p>

<p>That, and trying to understand what <a href="http://www.nhsilbert.net/">Noah Silbert</a> is going on about half the time.</p>

<p>So without further ado, I'm just going to launch into each chapter, throwing out my reactions and thoughts.</p>

<h2>Chapter 1</h2>

<p>This is a very short chapter, but a nice one to have.  It walks you through the structure of the book, and tries to assuage your fears that this book might be too much for you. In terms of prerequisites, Kruschke says that you don't really need any programming experience, and as long as you have a "dim knowledge of basic calculus," you should be fine.  I'm pretty sure my R skills will be up to snuff, but I will be a good test for his claims about calculus.  My knowledge (specifically, my memory of calculus from my high school course um... 18(!) years ago) is about as dim as it gets.  This chapter also gets you an intro to Kruschke's writing style, which is pretty goofy.  I mean that in a good way, though.  It's very conversational, and peppered with plenty of corny humor.  I imagine Kruschke's students groaning a lot (maybe on the inside, if they're respectful) in class, but staying awake because of it, and I suspect this will play out similarly in the book. I think this is probably a good thing, but we'll see.</p>

<p>One note, I didn't do an exhaustive search, but Kruschke gives HTTP addresses for both the Elsevier site and his personal site, and it looks like his personal site is where you should go to get programs, etc.  It's a little more scattered, visually, but his site is much more complete, and looks like it has a bunch of updated versions of programs, exercises, etc., where the Elsevier site has the more "basic" version of the code.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[NaBloPoMo and More Starting R]]></title>
    <link href="http://shoestringpsycholing.github.com/blog/2012/11/01/nablopomo-and-more-r/"/>
    <updated>2012-11-01T20:22:00-04:00</updated>
    <id>http://shoestringpsycholing.github.com/blog/2012/11/01/nablopomo-and-more-r</id>
    <content type="html"><![CDATA[<p>I'm using <a href="http://www.blogher.com/blogher-topics/blogging-social-media/nablopomo">NaBloPoMo</a> as an excuse to kick-start this blog into a little more action.  Let's see if I can keep it up the whole month...</p>

<p>Today was the second session of an <a href="http://shoestringpsycholing.github.com/blog/2012/10/25/starting-r/">R tutorial for beginners</a>.  This one went a bit more smoothly, I think.  I'll update my work-in-progress <a href="https://github.com/shoestringpsycholing/startR">startR</a> repo, if you're interested in the script.  I've done a few of these tutorial sessions now (for different audiences), and this one was the first time I really used an R script as a "script" in the more general sense of "scripted presentation."  In the past, I've had a kind of outline of things I want to cover, and I've usually run code, etc. to make sure things would work as expected beforehand, but when I'm actually in the middle of a tutorial, things inevitably go a little awry.  For me, usually in the form of annoying typos, in forgetting something or getting a little sidetracked, or sometimes even blanking on a particular function (last session I tried using <code>getwd()</code> and <code>setwd()</code>, but I rarely use those, and I was just sure they were <code>get.wd()</code> and <code>set.wd()</code>, and it totally threw me for a loop).</p>

<p>So this time I literally typed out every single thing in advance, in "walk-through" style, into a <code>.R</code> script, even things you'd normally never put in a script, like <code>head()</code> or <code>summary()</code>, and I think it really helped.  Not only did it save time and frustration by saving me from my inevitable typos, it helped me stay on track, and reminded me of all the little points I wanted to make, and the sequence in which I planned to make them.</p>

<p>I didn't get a whole lot of immediate feedback, but people seemed to be following a little better, and in general the reaction seemed more positive. Of course, even the most effective demo or lecture is only the very beginning of the learning process.  But I think a clear demo, set up to be run as an actual walk-through, is a pretty efficient way to present a fair amount of code without getting people lost in the process of having to fix your own mistakes on the fly. And I think when you're presenting to a group of more than just a couple of people (I think there were at least 20 or so tonight), a clear demo is about the best you can hope for.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Starting R]]></title>
    <link href="http://shoestringpsycholing.github.com/blog/2012/10/25/starting-r/"/>
    <updated>2012-10-25T21:13:00-04:00</updated>
    <id>http://shoestringpsycholing.github.com/blog/2012/10/25/starting-r</id>
    <content type="html"><![CDATA[<p><a href="http://www.r-project.org/">R</a> is a wonderful thing. It's also managed to consume my life, for better or for worse. I've been learning and working with R for about 5 years now, since finishing my PhD, and it's had a profound impact on my work, in a good way.</p>

<p>So naturally, I like to spread the love.  I've gotten a few friends hooked, and I like to help out other folks with what I've learned when I can.  Tonight I had a nice opportunity to give an intro tutorial to a group of grad students.  Boy, are my teaching chops rusty!</p>

<p>It went okay, maybe, possibly.  I got slowed down by some of the classic blunders (no, not a "land war in Asia," but maybe almost as bad).  But it's an interesting issue, really.  There are literally dozens and dozens of "intros to R" that you can find on the web, in print, or both.  Why try to make another one?  What can be improved on?  Why is it so difficult?</p>

<p>I had a nice plan.  Nice in my head, at least.  I'd get through a few of the basics, and then show off two really great things: the ease of merging data sets (for example, getting item and subject info merged into some raw data), and some of the nice ways to get some summary stats broken down by conditions.  Instead, we got tripped up by dumb things like "where's the file?" and "how do I change the working directory?".  "Dumb" in the sense of "dumb of me to not be better prepared for those," not that it's dumb to have those problems. Those problems are always the first ones to make people stumble and walk away, frustrated.</p>

<p>Luckily, I have another couple of chances to redeem myself.  We'll see how it goes.</p>

<p>If you want to follow along, you can check out my "startR" repo here on GitHub.  <a href="https://github.com/shoestringpsycholing/startR">Here's a link to it</a>, but there may also be a link off in the right hand bar of the blog.  Comments for improvements welcome!  I think my plan next time is to recap a little, but to try to walk through the workflow a little better.  I think one of the biggest initial hurdles is getting a sense of the R "ecology," for lack of a better term.</p>
]]></content>
  </entry>
  
</feed>
